{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MovieID to movie name mapping (Youtube Spencer Pao)\n",
    "movie_names= df_movies.set_index('movieId')['title'].to_dict()\n",
    "n_users = len(df_ratings.userId.unique())\n",
    "n_items = len(df_ratings.movieId.unique())\n",
    "print(\"Number of unique users:\", n_users)\n",
    "print(\"Number of unique movies:\", n_users)\n",
    "print(\"The ful rating matrix will have:\", n_users*n_items,'elements.')\n",
    "print('.............')\n",
    "print(\"Number of ratings:\",len(df_ratings))\n",
    "print(\"Therefore:\", len(df_ratings)/(n_users*n_items)*100, '% of the matrix is filled.') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        # Skapa användarinbäddningar\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
    "        # Skapa objektinbäddningar\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors)\n",
    "        self.user_factors.weight.data.uniform_(0, 0.05)\n",
    "        self.item_factors.weight.data.uniform_(0, 0.05)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        # Matrixmultiplikation\n",
    "        users, items = data[:, 0], data[:, 1]\n",
    "        user_embedding = self.user_factors(users)\n",
    "        item_embedding = self.item_factors(items)\n",
    "        return (user_embedding * item_embedding).sum(1)\n",
    "    \n",
    "    def predict(self, user, item):\n",
    "        return self.forward(torch.tensor([[user, item]], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data loader (nececery for PyTorch)\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader # package that helps transform your data to machine learning readiness\n",
    "\n",
    "class Loader(Dataset):\n",
    "    def __init__(self):\n",
    "        self.ratings = df_ratings.copy()\n",
    "        \n",
    "        #Extract all user IDs and movie IDs\n",
    "        users = df_ratings.userId.unique()\n",
    "        movies = df_ratings.movieId.unique()\n",
    "        \n",
    "        #Unique values: index\n",
    "        self.userid2idx = {i:i for i,o in enumerate(users)}\n",
    "        self.movieid2idx = {i:i for i,o in enumerate(movies)}\n",
    "        \n",
    "        #Obtiaind continuoues ID for users and movies\n",
    "        self.idx2userid = {i:o for o, i in self.userid2idx.items()}\n",
    "        self.idx2movieid = {i:o for o, i in self.movieid2idx.items()}\n",
    "        \n",
    "        #return the id from the index values as noted in the lambada function down below.\n",
    "        #self.ratings.movieId = df_ratings.movieId.apply(lambda x: self.movieid2idx[x])\n",
    "        #self.ratings.userId =df_ratings.userId.apply(lambda x: self.userid2idx[x])\n",
    "        #self.ratings.movieId = df_ratings.movieId.apply(lambda x: self.movieid2idx[x])\n",
    "        self.ratings.userId = df_ratings.userId.apply(lambda x: self.userid2idx.get(x, None))\n",
    "        self.ratings.movieId = df_ratings.movieId.apply(lambda x: self.movieid2idx.get(x, None))\n",
    "\n",
    "\n",
    "        \n",
    "        self.x = self.ratings.drop(['rating', 'timestamp'], axis=1).values\n",
    "        self.y =self.ratings['rating'].values\n",
    "        self.x , self.y = torch.tensor(self.x), torch.tensor(self.y) # Transforms the data to tensors(ready for torch models.)\n",
    "        \n",
    "    def __getitem__ (self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 128\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"Is running on GPU\", cuda)\n",
    "\n",
    "model = MatrixFactorization(n_users, n_items, n_factors=8)\n",
    "print(model)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "        \n",
    "#GPU enable if yu have a GPE...\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "# MSE loss\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "#ADM optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "\n",
    "#Train data\n",
    "train_set = Loader()\n",
    "train_loader = DataLoader(train_set, 128, shuffle = True)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "#Y= Ratings x UserId, MovieId\n",
    "\n",
    "for it in tqdm(range(num_epochs)):\n",
    "    losses = []\n",
    "    for x, y in train_loader:\n",
    "        if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            x = x.long()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = loss_fn(outputs.squeeze(), y.type(torch.float32))\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    #print()        \n",
    "    print(\"iter #{}\".format(it), \"Loss:\", sum(losses) / len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if losses:  # Kontrollera om losses inte är tom\n",
    "    print(\"iter #{}\".format(it), \"Loss:\", sum(losses) / len(losses))\n",
    "else:\n",
    "    print(\"iter #{}\".format(it), \"Loss: No losses calculated\")  # Hantera fallet när losses är tom\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
