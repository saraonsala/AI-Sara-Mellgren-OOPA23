{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movielens full - EDA\n",
    "a) Gör en EDA för att förstå datasetet. Inkludera olika slags plots. Begränsa dig inte till frågorna nedan,\n",
    "utan försök undersöka fler aspekter av datan.\n",
    "\n",
    "* Jag börjar med att undersöka vad datasetet har för columner med df.head och df.info()\n",
    "* Samt så har jag läst på \"Read me\" filen som tillhör datasetet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies= pd.read_csv(\"Data/ml-latest/movies.csv\")\n",
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86537 entries, 0 to 86536\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   movieId  86537 non-null  int64 \n",
      " 1   title    86537 non-null  object\n",
      " 2   genres   86537 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Jag tar df.info \n",
    "df_movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1225734739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1225865086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1225733503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1225735204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1225735119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1        1     4.0  1225734739\n",
       "1       1      110     4.0  1225865086\n",
       "2       1      158     4.0  1225733503\n",
       "3       1      260     4.5  1225735204\n",
       "4       1      356     5.0  1225735119"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings= pd.read_csv(\"Data/ml-latest/ratings.csv\")\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33832162 entries, 0 to 33832161\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   userId     int64  \n",
      " 1   movieId    int64  \n",
      " 2   rating     float64\n",
      " 3   timestamp  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 1.0 GB\n"
     ]
    }
   ],
   "source": [
    "df_ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 330975\n",
      "Number of unique movies: 330975\n",
      "The ful rating matrix will have: 27550028025 elements.\n",
      ".............\n",
      "Number of ratings: 33832162\n",
      "Therefore: 0.12280264096028991 % of the matrix is filled.\n"
     ]
    }
   ],
   "source": [
    "#MovieID to movie name mapping (Youtube Spencer Pao)\n",
    "movie_names= df_movies.set_index('movieId')['title'].to_dict()\n",
    "n_users = len(df_ratings.userId.unique())\n",
    "n_items = len(df_ratings.movieId.unique())\n",
    "print(\"Number of unique users:\", n_users)\n",
    "print(\"Number of unique movies:\", n_users)\n",
    "print(\"The ful rating matrix will have:\", n_users*n_items,'elements.')\n",
    "print('.............')\n",
    "print(\"Number of ratings:\",len(df_ratings))\n",
    "print(\"Therefore:\", len(df_ratings)/(n_users*n_items)*100, '% of the matrix is filled.') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        # Skapa användarinbäddningar\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
    "        # Skapa objektinbäddningar\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors)\n",
    "        self.user_factors.weight.data.uniform_(0, 0.05)\n",
    "        self.item_factors.weight.data.uniform_(0, 0.05)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        # Matrixmultiplikation\n",
    "        users, items = data[:, 0], data[:, 1]\n",
    "        user_embedding = self.user_factors(users)\n",
    "        item_embedding = self.item_factors(items)\n",
    "        return (user_embedding * item_embedding).sum(1)\n",
    "    \n",
    "    def predict(self, user, item):\n",
    "        return self.forward(torch.tensor([[user, item]], dtype=torch.long))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data loader (nececery for PyTorch)\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader # package that helps transform your data to machine learning readiness\n",
    "\n",
    "class Loader(Dataset):\n",
    "    def __init__(self):\n",
    "        self.ratings = df_ratings.copy()\n",
    "        \n",
    "        #Extract all user IDs and movie IDs\n",
    "        users = df_ratings.userId.unique()\n",
    "        movies = df_ratings.movieId.unique()\n",
    "        \n",
    "        #Unique values: index\n",
    "        self.userid2idx = {i:i for i,o in enumerate(users)}\n",
    "        self.movieid2idx = {i:i for i,o in enumerate(movies)}\n",
    "        \n",
    "        #Obtiaind continuoues ID for users and movies\n",
    "        self.idx2userid = {i:o for o, i in self.userid2idx.items()}\n",
    "        self.idx2movieid = {i:o for o, i in self.movieid2idx.items()}\n",
    "        \n",
    "        #return the id from the index values as noted in the lambada function down below.\n",
    "        #self.ratings.movieId = df_ratings.movieId.apply(lambda x: self.movieid2idx[x])\n",
    "        #self.ratings.userId =df_ratings.userId.apply(lambda x: self.userid2idx[x])\n",
    "        #self.ratings.movieId = df_ratings.movieId.apply(lambda x: self.movieid2idx[x])\n",
    "        self.ratings.userId = df_ratings.userId.apply(lambda x: self.userid2idx.get(x, None))\n",
    "        self.ratings.movieId = df_ratings.movieId.apply(lambda x: self.movieid2idx.get(x, None))\n",
    "\n",
    "\n",
    "        \n",
    "        self.x = self.ratings.drop(['rating', 'timestamp'], axis=1).values\n",
    "        self.y =self.ratings['rating'].values\n",
    "        self.x , self.y = torch.tensor(self.x), torch.tensor(self.y) # Transforms the data to tensors(ready for torch models.)\n",
    "        \n",
    "    def __getitem__ (self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is running on GPU False\n",
      "MatrixFactorization(\n",
      "  (user_factors): Embedding(330975, 8)\n",
      "  (item_factors): Embedding(83239, 8)\n",
      ")\n",
      "user_factors.weight tensor([[0.0167, 0.0351, 0.0042,  ..., 0.0484, 0.0329, 0.0490],\n",
      "        [0.0161, 0.0338, 0.0314,  ..., 0.0023, 0.0213, 0.0042],\n",
      "        [0.0376, 0.0420, 0.0476,  ..., 0.0474, 0.0320, 0.0144],\n",
      "        ...,\n",
      "        [0.0286, 0.0420, 0.0131,  ..., 0.0426, 0.0120, 0.0037],\n",
      "        [0.0383, 0.0317, 0.0439,  ..., 0.0291, 0.0081, 0.0066],\n",
      "        [0.0466, 0.0217, 0.0143,  ..., 0.0327, 0.0088, 0.0211]])\n",
      "item_factors.weight tensor([[0.0038, 0.0404, 0.0192,  ..., 0.0202, 0.0041, 0.0264],\n",
      "        [0.0405, 0.0069, 0.0312,  ..., 0.0078, 0.0252, 0.0100],\n",
      "        [0.0201, 0.0064, 0.0136,  ..., 0.0348, 0.0444, 0.0094],\n",
      "        ...,\n",
      "        [0.0157, 0.0274, 0.0356,  ..., 0.0289, 0.0093, 0.0166],\n",
      "        [0.0164, 0.0247, 0.0496,  ..., 0.0298, 0.0156, 0.0026],\n",
      "        [0.0225, 0.0219, 0.0166,  ..., 0.0370, 0.0385, 0.0056]])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 128\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"Is running on GPU\", cuda)\n",
    "\n",
    "model = MatrixFactorization(n_users, n_items, n_factors=8)\n",
    "print(model)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "        \n",
    "#GPU enable if yu have a GPE...\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "# MSE loss\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "#ADM optimizer\n",
    "optimizer = torch.nn.MSELoss()\n",
    "\n",
    "#Train data\n",
    "train_set = Loader()\n",
    "train_loader = DataLoader(train_set, 128, shuffle = True)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15364134af7f4077bbc662a02aeda070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #0 Loss: No losses calculated\n",
      "iter #1 Loss: No losses calculated\n",
      "iter #2 Loss: No losses calculated\n",
      "iter #3 Loss: No losses calculated\n",
      "iter #4 Loss: No losses calculated\n",
      "iter #5 Loss: No losses calculated\n",
      "iter #6 Loss: No losses calculated\n",
      "iter #7 Loss: No losses calculated\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_epochs)):\n\u001b[0;32m      4\u001b[0m     losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\USERS\\SARAM\\ONEDRIVE\\DOKUMENT\\GITHUB\\AI-SARA-MELLGREN-OOPA23\\VENV\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\USERS\\SARAM\\ONEDRIVE\\DOKUMENT\\GITHUB\\AI-SARA-MELLGREN-OOPA23\\VENV\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\USERS\\SARAM\\ONEDRIVE\\DOKUMENT\\GITHUB\\AI-SARA-MELLGREN-OOPA23\\VENV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\USERS\\SARAM\\ONEDRIVE\\DOKUMENT\\GITHUB\\AI-SARA-MELLGREN-OOPA23\\VENV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\USERS\\SARAM\\ONEDRIVE\\DOKUMENT\\GITHUB\\AI-SARA-MELLGREN-OOPA23\\VENV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\USERS\\SARAM\\ONEDRIVE\\DOKUMENT\\GITHUB\\AI-SARA-MELLGREN-OOPA23\\VENV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\USERS\\SARAM\\ONEDRIVE\\DOKUMENT\\GITHUB\\AI-SARA-MELLGREN-OOPA23\\VENV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\USERS\\SARAM\\ONEDRIVE\\DOKUMENT\\GITHUB\\AI-SARA-MELLGREN-OOPA23\\VENV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for it in tqdm(range(num_epochs)):\n",
    "    losses = []\n",
    "    for x, y in train_loader:\n",
    "        if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            x = x.long()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = loss_fn(outputs.squeeze(), y.type(torch.float32))\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Kontrollera om losses inte är tom\n",
    "    if losses:\n",
    "        print(\"iter #{}\".format(it), \"Loss:\", sum(losses) / len(losses))\n",
    "    else:\n",
    "        print(\"iter #{}\".format(it), \"Loss: No losses calculated\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #0 Loss: No losses calculated\n"
     ]
    }
   ],
   "source": [
    "if losses:  # Kontrollera om losses inte är tom\n",
    "    print(\"iter #{}\".format(it), \"Loss:\", sum(losses) / len(losses))\n",
    "else:\n",
    "    print(\"iter #{}\".format(it), \"Loss: No losses calculated\")  # Hantera fallet när losses är tom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jag ser att jag behöver splita cellerna så att i genders och film titel delas upp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Children</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId             title     genres  year\n",
       "0        1  Toy Story (1995)  Adventure  1995\n",
       "0        1  Toy Story (1995)  Animation  1995\n",
       "0        1  Toy Story (1995)   Children  1995\n",
       "0        1  Toy Story (1995)     Comedy  1995\n",
       "0        1  Toy Story (1995)    Fantasy  1995"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies = df_movies.assign(year=df_movies ['title'].str.extract(r'\\((\\d{4})\\)'), title=df_movies ['title'].str.replace(r'\\(\\d{4}\\)', '').str.strip())\n",
    "\n",
    "df_movies['genres'] = df_movies['genres'].str.split('|')\n",
    "df_movies= df_movies.explode('genres')\n",
    "\n",
    "df_movies.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Vilka är de 10 filmerna med flest ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utför sammanslagning samt kolumner samt återställt indexet till 'movieId'\n",
    "#merged_df = pd.merge(df_ratings, df_movies, on='movieId')[['movieId', 'title', 'genres', 'rating', 'timestamp']]\n",
    "#merged_df = merged_df.set_index('movieId').reset_index()\n",
    "\n",
    "# Gruppera efter filmtitel och räkna antalet betyg för varje film\n",
    "#top_movies = merged_df.groupby('title').size().reset_index(name='rating_count')\n",
    "\n",
    "# Sortera resultaten i fallande ordning baserat på antalet betyg och välj de 10 första raderna\n",
    "#top_10_movies = top_movies.sort_values(by='rating_count', ascending=False).head(10)\n",
    "\n",
    "#print(top_10_movies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Beräkna den genomsnittliga ratingen för dessa 10 filmerna med flest ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n",
      "Fight Club (1999)                   4.236019\n",
      "Forrest Gump (1994)                 4.068189\n",
      "Inception (2010)                    4.176187\n",
      "Jurassic Park (1993)                3.689013\n",
      "Lion King, The (1994)               3.833477\n",
      "Matrix, The (1999)                  4.160631\n",
      "Pulp Fiction (1994)                 4.191778\n",
      "Shrek (2001)                        3.748595\n",
      "Silence of the Lambs, The (1991)    4.150287\n",
      "Toy Story (1995)                    3.893508\n",
      "Name: rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "avg_rating_top_10 = top_10_movies.merge(merged_df, on='title').groupby('title')['rating'].mean()\n",
    "\n",
    "print(avg_rating_top_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Gör en plot över årtal och antalet filmer representerade i datasetet.\n",
    "\n",
    "Jag tar filtrerar ut så att ploten bara visar filmer från 1950 och framåt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId             title     genres  rating   timestamp\n",
      "0        1  Toy Story (1995)  Adventure     4.0  1225734739\n",
      "1        1  Toy Story (1995)  Animation     4.0  1225734739\n",
      "2        1  Toy Story (1995)   Children     4.0  1225734739\n",
      "3        1  Toy Story (1995)     Comedy     4.0  1225734739\n",
      "4        1  Toy Story (1995)    Fantasy     4.0  1225734739\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    9.211335e+07\n",
      "mean     1.277818e+09\n",
      "std      2.529235e+08\n",
      "min      7.896520e+08\n",
      "25%      1.060876e+09\n",
      "50%      1.284173e+09\n",
      "75%      1.500351e+09\n",
      "max      1.689843e+09\n",
      "Name: timestamp, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(merged_df['timestamp'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "e) Gör en plot över antalet ratings mot movieId.\n",
    "\n",
    "f) Beräkna genomsnittliga ratings för de top 10 filmerna med flest ratings. Gör ett stapeldiagram över\n",
    "dessa.\n",
    "\n",
    "1.2 Skapa gles matris\n",
    "\n",
    "Likt i videon i uppgift 1.0 skapade du en pivottabell av dataframet med index: \"movieId\", columns: \"userId\"\n",
    "och values: \"ratings\". Denna pivottabell är dock \"dyr\" att skapa och förmodligen kommer inte din dator att\n",
    "klara av skapa den om du inte filtrerar bort viss data. Fundera ut ett lämpligt sätt att filtrera ditt dataset,\n",
    "pröva dig fram och motivera.#\n",
    "\n",
    "Skapa en gles (sparse) matris av denna pivottabell mha scipy.sparse.csc_matrix(). Vill du använda\n",
    "dig av all data går det också att lösa, men du behöver lösa hur du skapar den glesa matrisen utan pandas\n",
    "pivot-tabell.\n",
    "\n",
    " 1.3 Recommender system\n",
    "\n",
    "Skapa ett recommender system med KNN och låt systemet ta input från användaren och skriva ut top 5\n",
    "rekommenderade filmerna, baserat på användarens sökquery. Observera att det finns ett logiskt fel i\n",
    "videon som gör att rekommendationerna inte blir så bra, försök hitta felet och åtgärda det.\n",
    "\n",
    "a) Beskriv med ord hur ditt system fungerar.\n",
    "\n",
    "b) Leta online och läs vidare om rekommenderarsystem och beskriv kort hur dem fungerar. Glöm inte\n",
    "källhänvisa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
